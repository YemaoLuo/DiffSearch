a9d708aa5475ed80622a6991fedded14fdcbec7b
==================================================
Implement limits for HTTP/2 header size and count
==================================================
Mark Thomas
==================================================
Thu Oct 20 11:06:41 2016 +0000
==================================================
Constants.java
Implement limits for HTTP/2 header size and count

git-svn-id: https://svn.apache.org/repos/asf/tomcat/trunk@1765801 13f79535-47bb-0310-9956-ffa450edef68



==================================================
HpackDecoder.java
index 61e2a32d2c..11322bf8f0 100644
--- a/java/org/apache/coyote/http2/Constants.java
+++ b/java/org/apache/coyote/http2/Constants.java
@@ -23,4 +23,8 @@ public class Constants {
 
     // Parsing
     static final int DEFAULT_HEADER_READ_BUFFER_SIZE = 1024;
+
+    // Limits
+    static final int DEFAULT_MAX_HEADER_COUNT = 100;
+    static final int DEFAULT_MAX_HEADER_SIZE = 8 * 1024;
 }

==================================================
Http2Parser.java
index 699b1d27c6..95d83426c8 100644
--- a/java/org/apache/coyote/http2/HpackDecoder.java
+++ b/java/org/apache/coyote/http2/HpackDecoder.java
@@ -61,6 +61,13 @@ public class HpackDecoder {
      */
     private int maxMemorySize;
 
+    private int maxHeaderCount = Constants.DEFAULT_MAX_HEADER_COUNT;
+    private int maxHeaderSize = Constants.DEFAULT_MAX_HEADER_SIZE;
+
+    private volatile int headerCount = 0;
+    private volatile boolean countedCookie;
+    private volatile int headerSize = 0;
+
     private final StringBuilder stringBuilder = new StringBuilder();
 
     HpackDecoder(int maxMemorySize) {
@@ -109,7 +116,7 @@ public class HpackDecoder {
                     buffer.position(originalPos);
                     return;
                 }
-                headerEmitter.emitHeader(headerName, headerValue);
+                emitHeader(headerName, headerValue);
                 addEntryToHeaderTable(new Hpack.HeaderField(headerName, headerValue));
             } else if ((b & 0b11110000) == 0) {
                 //Literal Header Field without Indexing
@@ -123,7 +130,7 @@ public class HpackDecoder {
                     buffer.position(originalPos);
                     return;
                 }
-                headerEmitter.emitHeader(headerName, headerValue);
+                emitHeader(headerName, headerValue);
             } else if ((b & 0b11110000) == 0b00010000) {
                 //Literal Header Field never indexed
                 String headerName = readHeaderName(buffer, 4);
@@ -136,7 +143,7 @@ public class HpackDecoder {
                     buffer.position(originalPos);
                     return;
                 }
-                headerEmitter.emitHeader(headerName, headerValue);
+                emitHeader(headerName, headerValue);
             } else if ((b & 0b11100000) == 0b00100000) {
                 //context update max table size change
                 if (!handleMaxMemorySizeChange(buffer, originalPos)) {
@@ -246,7 +253,7 @@ public class HpackDecoder {
         } else {
             int adjustedIndex = getRealIndex(index - Hpack.STATIC_TABLE_LENGTH);
             Hpack.HeaderField headerField = headerTable[adjustedIndex];
-            headerEmitter.emitHeader(headerField.name, headerField.value);
+            emitHeader(headerField.name, headerField.value);
         }
     }
 
@@ -273,7 +280,7 @@ public class HpackDecoder {
         if (entry.value == null) {
             throw new HpackException();
         }
-        headerEmitter.emitHeader(entry.name, entry.value);
+        emitHeader(entry.name, entry.value);
     }
 
     private void addEntryToHeaderTable(Hpack.HeaderField entry) {
@@ -354,10 +361,74 @@ public class HpackDecoder {
         return headerEmitter;
     }
 
+
     void setHeaderEmitter(HeaderEmitter headerEmitter) {
         this.headerEmitter = headerEmitter;
+        // Reset limit tracking
+        headerCount = 0;
+        countedCookie = false;
+        headerSize = 0;
+    }
+
+
+    void setMaxHeaderCount(int maxHeaderCount) {
+        this.maxHeaderCount = maxHeaderCount;
+    }
+
+
+    void setMaxHeaderSize(int maxHeaderSize) {
+        this.maxHeaderSize = maxHeaderSize;
+    }
+
+
+    private void emitHeader(String name, String value) {
+        // Header names are forced to lower case
+        if ("cookie".equals(name)) {
+            // Only count the cookie header once since HTTP/2 splits it into
+            // multiple headers to aid compression
+            if (!countedCookie) {
+                headerCount ++;
+                countedCookie = true;
+            }
+        } else {
+            headerCount ++;
+        }
+        // Overhead will vary. The main concern is that lots of small headers
+        // trigger the limiting mechanism correctly. Therefore, use an overhead
+        // estimate of 3 which is the worst case for small headers.
+        int inc = 3 + name.length() + value.length();
+        headerSize += inc;
+        if (!isHeaderCountExceeded() && !isHeaderSizeExceeded(0)) {
+            headerEmitter.emitHeader(name, value);
+        }
     }
 
+
+    boolean isHeaderCountExceeded() {
+        if (maxHeaderCount < 0) {
+            return false;
+        }
+        return headerCount > maxHeaderCount;
+    }
+
+
+    boolean isHeaderSizeExceeded(int unreadSize) {
+        if (maxHeaderSize < 0) {
+            return false;
+        }
+        return (headerSize + unreadSize) > maxHeaderSize;
+    }
+
+
+    boolean isHeaderSwallowSizeExceeded(int unreadSize) {
+        if (maxHeaderSize < 0) {
+            return false;
+        }
+        // Swallow the same again before closing the connection.
+        return (headerSize + unreadSize) > (2 * maxHeaderSize);
+    }
+
+
     //package private fields for unit tests
 
     int getFirstSlotPosition() {

==================================================
Http2Protocol.java
index 78f05a5a5f..bdd0263365 100644
--- a/java/org/apache/coyote/http2/Http2Parser.java
+++ b/java/org/apache/coyote/http2/Http2Parser.java
@@ -45,7 +45,7 @@ class Http2Parser {
             ByteBuffer.allocate(Constants.DEFAULT_HEADER_READ_BUFFER_SIZE);
     private volatile int headersCurrentStream = -1;
     private volatile boolean headersEndStream = false;
-
+    private volatile boolean streamReset = false;
 
     Http2Parser(String connectionId, Input input, Output output) {
         this.connectionId = connectionId;
@@ -243,7 +243,7 @@ class Http2Parser {
             payloadSize -= padLength;
         }
 
-        readHeaderPayload(payloadSize);
+        readHeaderPayload(streamId, payloadSize);
 
         swallow(streamId, padLength, true);
 
@@ -371,7 +371,7 @@ class Http2Parser {
                     Integer.toString(streamId)), Http2Error.PROTOCOL_ERROR);
         }
 
-        readHeaderPayload(payloadSize);
+        readHeaderPayload(streamId, payloadSize);
 
         if (Flags.isEndOfHeaders(flags)) {
             onHeadersComplete(streamId);
@@ -380,7 +380,13 @@ class Http2Parser {
     }
 
 
-    private void readHeaderPayload(int payloadSize) throws Http2Exception, IOException {
+    private void readHeaderPayload(int streamId, int payloadSize)
+            throws Http2Exception, IOException {
+
+        if (log.isDebugEnabled()) {
+            log.debug(sm.getString("http2Parser.processFrameHeaders.payload", connectionId,
+                    Integer.valueOf(streamId), Integer.valueOf(payloadSize)));
+        }
 
         int remaining = payloadSize;
 
@@ -411,9 +417,27 @@ class Http2Parser {
                         sm.getString("http2Parser.processFrameHeaders.decodingFailed"),
                         Http2Error.COMPRESSION_ERROR);
             }
+
             // switches to write mode
             headerReadBuffer.compact();
             remaining -= toRead;
+
+            if (hpackDecoder.isHeaderCountExceeded() && !streamReset) {
+                streamReset = true;
+                throw new StreamException(sm.getString("http2Parser.headerLimitCount", connectionId,
+                        Integer.valueOf(streamId)), Http2Error.ENHANCE_YOUR_CALM, streamId);
+            }
+
+            if (hpackDecoder.isHeaderSizeExceeded(headerReadBuffer.position()) && !streamReset) {
+                streamReset = true;
+                throw new StreamException(sm.getString("http2Parser.headerLimitSize", connectionId,
+                        Integer.valueOf(streamId)), Http2Error.ENHANCE_YOUR_CALM, streamId);
+            }
+
+            if (hpackDecoder.isHeaderSwallowSizeExceeded(headerReadBuffer.position())) {
+                throw new ConnectionException(sm.getString("http2Parser.headerLimitSize",
+                        connectionId, Integer.valueOf(streamId)), Http2Error.ENHANCE_YOUR_CALM);
+            }
         }
 
         hpackDecoder.getHeaderEmitter().validateHeaders();
@@ -439,6 +463,11 @@ class Http2Parser {
         if (headerReadBuffer.capacity() > Constants.DEFAULT_HEADER_READ_BUFFER_SIZE) {
             headerReadBuffer = ByteBuffer.allocate(Constants.DEFAULT_HEADER_READ_BUFFER_SIZE);
         }
+
+        // Clear the 'stream has been reset' flag, if set
+        if (streamReset) {
+            streamReset = false;
+        }
     }
 
 

==================================================
Http2UpgradeHandler.java
index 381b323c5e..3acdb1108a 100644
--- a/java/org/apache/coyote/http2/Http2Protocol.java
+++ b/java/org/apache/coyote/http2/Http2Protocol.java
@@ -61,8 +61,11 @@ public class Http2Protocol implements UpgradeProtocol {
     // If a lower initial value is required, set it here but DO NOT change the
     // default defined above.
     private int initialWindowSize = DEFAULT_INITIAL_WINDOW_SIZE;
+    // Limits
     private Set<String> allowedTrailerHeaders =
             Collections.newSetFromMap(new ConcurrentHashMap<String, Boolean>());
+    private int maxHeaderCount = Constants.DEFAULT_MAX_HEADER_COUNT;
+    private int maxHeaderSize = Constants.DEFAULT_MAX_HEADER_SIZE;
 
 
     @Override
@@ -104,6 +107,8 @@ public class Http2Protocol implements UpgradeProtocol {
         result.setMaxConcurrentStreamExecution(getMaxConcurrentStreamExecution());
         result.setInitialWindowSize(getInitialWindowSize());
         result.setAllowedTrailerHeaders(allowedTrailerHeaders);
+        result.setMaxHeaderCount(getMaxHeaderCount());
+        result.setMaxHeaderSize(getMaxHeaderSize());
         return result;
     }
 
@@ -227,4 +232,24 @@ public class Http2Protocol implements UpgradeProtocol {
         }
         return result.toString();
     }
+
+
+    public void setMaxHeaderCount(int maxHeaderCount) {
+        this.maxHeaderCount = maxHeaderCount;
+    }
+
+
+    public int getMaxHeaderCount() {
+        return maxHeaderCount;
+    }
+
+
+    public void setMaxHeaderSize(int maxHeaderSize) {
+        this.maxHeaderSize = maxHeaderSize;
+    }
+
+
+    public int getMaxHeaderSize() {
+        return maxHeaderSize;
+    }
 }

==================================================
TestHttp2Limits.java
index 3237fede01..cd4bb5a8fe 100644
--- a/java/org/apache/coyote/http2/LocalStrings.properties
+++ b/java/org/apache/coyote/http2/LocalStrings.properties
@@ -39,6 +39,8 @@ hpackEncoder.encodeHeader=Encoding header [{0}] with value [{1}]
 
 hpackhuffman.huffmanEncodedHpackValueDidNotEndWithEOS=Huffman encoded value in HPACK headers did not end with EOS padding
 
+http2Parser.headerLimitCount=Connection [{0}], Stream [{1}], Too many headers
+http2Parser.headerLimitSize=Connection [{0}], Stream [{1}], Total header size too big
 http2Parser.headers.wrongFrameType=Connection [{0}], headers in progress for stream [{1}] but a frame of type [{2}] was received
 http2Parser.headers.wrongStream=Connection [{0}], headers in progress for stream [{1}] but a frame for stream [{2}] was received
 http2Parser.nonZeroPadding=Connection [{0}], Stream [{1}], Non-zero padding received
@@ -53,6 +55,7 @@ http2Parser.processFrameData.lengths=Connection [{0}], Stream [{1}], Data length
 http2Parser.processFrameGoaway.payloadTooSmall=Connection [{0}]: Goaway payload size was [{1}] which is less than the minimum 8
 http2Parser.processFrameHeaders.decodingFailed=There was an error during the HPACK decoding of HTTP headers
 http2Parser.processFrameHeaders.decodingDataLeft=Data left over after HPACK decoding - it should have been consumed
+http2Parser.processFrameHeaders.payload=Connection [{0}], Stream [{1}], Processing headers payload size [{2}]
 http2Parser.processFramePing.invalidPayloadSize=Settings frame received with an invalid payload size of [{0}] (should be 8)
 http2Parser.processFramePriority.invalidParent=Connection [{0}], Stream [{1}], A stream may not depend on itself
 http2Parser.processFramePriority.invalidPayloadSize=Priority frame received with an invalid payload size of [{0}] (should be 5)

==================================================
